{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Notebook for running Herlands et. al's algorithm against our simulation scenarios. Forked from their `real_data_general.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import statsmodels.formula.api as smf  # for doing statistical regression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.discrete.discrete_model as smd\n",
    "\n",
    "from data_functions import *\n",
    "from subset_functions import *\n",
    "from model_functions import *\n",
    "from search_functions import *\n",
    "from analysis_functions import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "\n",
    "dir_results = '../results/'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_RDSS(dir_data, file_json, subsample, plotting_data, verbose_data, obs_model, data_type, f_base, k, verbose_search, plotting_search):\n",
    "\n",
    "    seed = 43\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Get data\n",
    "    x, y, z, T, x_cols, inst, discont = data_real(dir_data, file_json, subsample=subsample, plotting=plotting_data, verbose=verbose_data)\n",
    "\n",
    "    # Search for discontinuity\n",
    "    x, x_means, x_stds = normalize_xz(x, z)\n",
    "    llrs, neighs, subsets_best, beta_0_n, beta_1_n, T_fx, llrs_n, llrs_a, centers_n, pivots_best, subset_imax = \\\n",
    "    RDSS_residual(obs_model, T, x, z, f_base=f_base, all_points=False, k=k, verbose=verbose_search, plotting=plotting_search)\n",
    "    x = unnormalize_xz(x, z, x_means, x_stds)\n",
    "\n",
    "    # Plot the best\n",
    "    max_arg = np.argmax(llrs)\n",
    "    plot_neigh(x, z, out=T, out_name='Top subset', neigh=[subset_neigh(neighs[:,max_arg], subsets_best[max_arg]),subset_neigh(neighs[:,max_arg], ~subsets_best[max_arg])])\n",
    "    plt.hist(llrs, bins=100); plt.show()\n",
    "    \n",
    "    # randomization testing\n",
    "    iters_rand = 20\n",
    "    alpha = 0.05\n",
    "    k_samples = k\n",
    "\n",
    "    T_hat_master = get_pred_mean(T_fx, f_base, x)\n",
    "\n",
    "    llr_sig, llr_max_samples, llr_all_samples = rand_testing(obs_model, T_fx, T_hat_master,\n",
    "                                            k_samples, iters_rand, \n",
    "                                            alpha, T, x, z, f_base,\n",
    "                                            all_points=False, k=[k])\n",
    "\n",
    "    plot_neigh(x, z, llrs>llr_sig, 'LLR -- significant at alpha '+str(alpha))\n",
    "    \n",
    "    return llrs, neighs, subsets_best, beta_0_n, beta_1_n, T_fx, llrs_n, llrs_a, centers_n, pivots_best, subset_imax, llr_sig, llr_max_samples, llr_all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_points(dir_data, file_json, subsample, plotting_data, verbose_data, obs_model, data_type, f_base, k, verbose_search, plotting_search, seed=42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Get data\n",
    "    x, y, z, T, x_cols, inst, discont = data_real(dir_data, file_json, subsample=subsample, plotting=plotting_data, verbose=verbose_data)\n",
    "\n",
    "    # Search for discontinuity\n",
    "    x, x_means, x_stds = normalize_xz(x, z)\n",
    "    llrs, neighs, subsets_best, beta_0_n, beta_1_n, T_fx, llrs_n, llrs_a, centers_n, pivots_best, subset_imax = \\\n",
    "    RDSS_residual(obs_model, T, x, z, f_base=f_base, all_points=False, k=k, verbose=verbose_search, plotting=plotting_search)\n",
    "    x = unnormalize_xz(x, z, x_means, x_stds)\n",
    "\n",
    "    # Plot the best\n",
    "    #max_arg = np.argmax(llrs)\n",
    "    #plot_neigh(x, z, out=T, out_name='Top subset', neigh=[subset_neigh(neighs[:,max_arg], subsets_best[max_arg]),subset_neigh(neighs[:,max_arg], ~subsets_best[max_arg])])\n",
    "    #plt.hist(llrs, bins=100); plt.show()\n",
    "    \n",
    "    # randomization testing, multiple test correction\n",
    "    iters_rand = 20\n",
    "    alpha = 0.05 / k \n",
    "    k_samples = k\n",
    "    print(alpha)\n",
    "    \n",
    "    T_hat_master = get_pred_mean(T_fx, f_base, x)\n",
    "\n",
    "    llr_sig, llr_max_samples, llr_all_samples = rand_testing(obs_model, T_fx, T_hat_master,\n",
    "                                            k_samples, iters_rand, \n",
    "                                            alpha, T, x, z, f_base,\n",
    "                                            all_points=False, k=[k])\n",
    "\n",
    "    #plot_neigh(x, z, llrs>llr_sig, 'LLR -- significant at alpha '+str(alpha))\n",
    "    x, y, z, T, x_cols, inst, discont = data_real(dir_data, file_json, subsample=subsample, plotting=plotting_data, verbose=verbose_data)\n",
    "    \n",
    "    return x[llrs > llr_sig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 0.25\n",
    "c2 = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sim(gap, seed):\n",
    "    \"\"\"\n",
    "    Runs simulation of Herlands for a given gap and seed.\n",
    "    \n",
    "    Returns:\n",
    "        (bool, bool, int): c1 in cutpoints, c2 in cutpoints, number of significant points\n",
    "    \"\"\"\n",
    "    dir_data = 'blend_sim'\n",
    "    file_json = f\"blend_sim_gap{gap}_seed{seed}.json\"\n",
    "    \n",
    "    meta_dict = {\"file\": [f\"gap{gap}_seed{seed}.csv\"], \n",
    "                 \"x\": [\"x\", \"covar\"], \n",
    "                 \"z\": [\"x\", \"covar\"], \n",
    "                 \"T\": [\"t\"], \n",
    "                 \"y\": [\"p\"]}\n",
    "    \n",
    "    # migrate prep_real_data.py functionality to here\n",
    "    with open(f\"../data/{dir_data}/{file_json}\", \"w\") as f:\n",
    "        json.dump(meta_dict, f)\n",
    "    \n",
    "    #subsample = 100 # for testing\n",
    "    subsample = False\n",
    "\n",
    "    plotting_data = False\n",
    "    verbose_data = False\n",
    "\n",
    "    # Search\n",
    "    obs_model = 'normal'    # {'normal', 'bernoulli'}\n",
    "    data_type ='binary'        # {'cont', 'binary'}\n",
    "    f_base    = 'Logit_poly1'  # {'OLS_poly1', 'Logit_poly1',\n",
    "    k = 100\n",
    "    verbose_search = False\n",
    "    plotting_search = False\n",
    "\n",
    "    sig_x = get_sig_points(dir_data, file_json, subsample, plotting_data, verbose_data, obs_model, data_type, f_base, k, verbose_search, plotting_search, seed=seed)\n",
    "    \n",
    "    sig_x = np.round(sig_x, 2)\n",
    "    #print(sig_x)\n",
    "    return c1 in list(sig_x[0]), c2 in list(sig_x[0]), sig_x.shape[0], sig_x[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%%capture\n",
    "import multiprocessing\n",
    "import contextlib\n",
    "\n",
    "gaps = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "starts = [0, 100, 200, 300, 400]\n",
    "\n",
    "out_path = \"{0}seed{1}/herlands_results_gap{2}.pkl\"\n",
    "\n",
    "for start in starts:\n",
    "    seeds = range(start, start+100)\n",
    "    for gap in gaps:\n",
    "        args = [(gap, seed) for seed in seeds]\n",
    "        with multiprocessing.Pool(20) as pool:\n",
    "            #with open(os.devnull, \"w\") as f, contextlib.redirect_stderr(f):\n",
    "            results = pool.starmap(run_sim, args)\n",
    "            pickle.dump(results, open(out_path.format(dir_results, start, gap), \"wb\"), -1)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
