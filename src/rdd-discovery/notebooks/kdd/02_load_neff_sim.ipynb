{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for loading simulation results from updated neff experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# user imports\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from utils.pwr import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load simulated results data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 500\n",
    "fuzzy_gaps = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "alpha = 0.05\n",
    "\n",
    "low_cutoff = 0.25\n",
    "hi_cutoff = 0.75\n",
    "\n",
    "seeds = range(0, 401, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"../../results/kdd23/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:11<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "baseline_result_dict = {}\n",
    "\n",
    "for fuzzy_gap in tqdm(fuzzy_gaps):\n",
    "    error_dict = {\n",
    "        'x': {\n",
    "            'fp': 0,\n",
    "            'lower_fn': 0,\n",
    "            'upper_fn': 0\n",
    "        },\n",
    "\n",
    "        'covar': {\n",
    "            'fp': 0\n",
    "        },\n",
    "    }\n",
    "    pvals = {}\n",
    "    for seed in seeds:\n",
    "        with open(f\"../../experiments/kdd/baseline_discovery/seed{seed}/blended_rdd_fixed_bw_{fuzzy_gap}.pkl\", \"rb\") as f:\n",
    "            results = pickle.load(f)\n",
    "            for result in results:\n",
    "                x_thresholds = [np.round(c, decimals=2) for c in result['x'].keys()]\n",
    "                if low_cutoff not in x_thresholds:\n",
    "                    error_dict['x']['lower_fn'] += 1\n",
    "                else: \n",
    "                    x_thresholds.remove(0.25)\n",
    "\n",
    "                if hi_cutoff not in x_thresholds:\n",
    "                    error_dict['x']['upper_fn'] += 1\n",
    "                else:\n",
    "                    x_thresholds.remove(0.75)\n",
    "\n",
    "                error_dict['x']['fp'] += len(x_thresholds)\n",
    "                error_dict['covar']['fp'] += len(result['covar'].keys())\n",
    "\n",
    "            \n",
    "    baseline_result_dict[fuzzy_gap] = error_dict       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(baseline_result_dict, open(os.path.join(RESULTS_DIR, \"blend_baseline_results.dict\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subgroup discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dir = \"/data/REDACTED/rdsgd/subgroup/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subgroup_tree_results(fuzzy_gap, seeds):\n",
    "    \"\"\"Process subgroup tree results\"\"\"\n",
    "    pvals = {\n",
    "        'trial': [],\n",
    "        'cutoff': [],\n",
    "        'tau_pval': [],\n",
    "        'neff_pval': [],\n",
    "        'rule_length': [],\n",
    "    }\n",
    "    for seed in seeds:\n",
    "        with open(os.path.join(sim_dir, f\"seed{seed}_blended_rdd_fixed_bw_{fuzzy_gap}.pkl\"), \"rb\") as f:\n",
    "            result, n_tests = pickle.load(f)    \n",
    "            \n",
    "            x_dict = result['x']\n",
    "            x_thresholds = [np.round(c, decimals=2) for c in x_dict.keys()]\n",
    "            \n",
    "            for x_cutoff in x_thresholds:\n",
    "                nodes = x_dict[x_cutoff]\n",
    "                \n",
    "                for node in nodes:\n",
    "                    if node['llr_results'] is None:\n",
    "                        continue\n",
    "                \n",
    "                    pvals['trial'].append(seed)\n",
    "                    pvals['cutoff'].append(x_cutoff)\n",
    "                    pvals['neff_pval'].append(node['neff_pval'])\n",
    "                    pvals['tau_pval'].append(node['llr_results'].pvalues['z'])\n",
    "                    pvals['rule_length'].append(len(node['rule_path']))\n",
    "                    #pvals[seed]['x_all'][x_cutoff].append((node['llr_results'].pvalues['z'], node['neff_pval'], len(node['rule_path'])))\n",
    "    \n",
    "    pval_df = pd.DataFrame.from_dict(pvals)\n",
    "    pval_df['fuzzy_gap'] = fuzzy_gap\n",
    "    return pval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in sqrt\n",
      "invalid value encountered in sqrt\n",
      "invalid value encountered in sqrt\n",
      "invalid value encountered in sqrt\n",
      "invalid value encountered in sqrt\n",
      "invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 93.7 ms, sys: 216 ms, total: 310 ms\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#subgroup_results_dict = {}\n",
    "\n",
    "seeds = range(0, n_trials)\n",
    "\n",
    "f_args = [(fuzzy_gap, seeds) for fuzzy_gap in fuzzy_gaps]\n",
    "with multiprocessing.Pool(8) as p:\n",
    "    results = p.starmap(process_subgroup_tree_results, f_args)\n",
    "\n",
    "#subgroup_results_dict = {fuzzy_gap: pvals for fuzzy_gap, pvals in results}\n",
    "pval_df = pd.concat(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>cutoff</th>\n",
       "      <th>tau_pval</th>\n",
       "      <th>neff_pval</th>\n",
       "      <th>rule_length</th>\n",
       "      <th>fuzzy_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.249188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.018973</td>\n",
       "      <td>1.259842e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.777216</td>\n",
       "      <td>9.696829e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.607564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.323746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17033</th>\n",
       "      <td>499</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.293436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17034</th>\n",
       "      <td>499</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.028985</td>\n",
       "      <td>1.983412e+00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17035</th>\n",
       "      <td>499</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.837292</td>\n",
       "      <td>8.638401e-11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17036</th>\n",
       "      <td>499</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.081328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17037</th>\n",
       "      <td>499</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.576076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108172 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       trial  cutoff  tau_pval     neff_pval  rule_length  fuzzy_gap\n",
       "0          0    0.05  0.249188           NaN            1        0.2\n",
       "1          0    0.05  0.018973  1.259842e+00            2        0.2\n",
       "2          0    0.05  0.777216  9.696829e-01            2        0.2\n",
       "3          0    0.10  0.607564           NaN            1        0.2\n",
       "4          0    0.15  0.323746           NaN            1        0.2\n",
       "...      ...     ...       ...           ...          ...        ...\n",
       "17033    499    0.85  0.293436           NaN            1        0.7\n",
       "17034    499    0.85  0.028985  1.983412e+00            2        0.7\n",
       "17035    499    0.85  0.837292  8.638401e-11            2        0.7\n",
       "17036    499    0.90  0.081328           NaN            1        0.7\n",
       "17037    499    0.95  0.576076           NaN            1        0.7\n",
       "\n",
       "[108172 rows x 6 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_df.to_pickle(os.path.join(RESULTS_DIR, \"subgroup_neff_pval.df\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute corrected p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:06<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "low_cutoff = 0.25\n",
    "upper_cutoff = 0.75\n",
    "\n",
    "#tp_all = {}\n",
    "\n",
    "nb_dict = {}\n",
    "\n",
    "subgroup_trial_dict = {}\n",
    "\n",
    "#pval_df = result_dict['x_all']\n",
    "#pval_df.shape\n",
    "for gap in tqdm(fuzzy_gaps):\n",
    "    gap_dict = {\n",
    "        'upper_tp': 0,\n",
    "        'lower_tp': 0,\n",
    "        'fp': 0,\n",
    "        'tot_tests': 0,\n",
    "        'tot_upper_tp': 0,\n",
    "        'tot_lower_tp': 0,\n",
    "        #'fp_cutoffs': set()\n",
    "    }\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        trial_df = pval_df[(pval_df['trial'] == trial) & (pval_df['fuzzy_gap'] == gap)]\n",
    "        gap_dict['tot_tests'] += trial_df.shape[0]\n",
    "        \n",
    "        method = 'bonf'\n",
    "        #reject_neff, _ = pg.multicomp(list(trial_df['neff_pval']), method=method, alpha=alpha)\n",
    "        reject_neff = trial_df['neff_pval'] < alpha\n",
    "        reject_z, _ = pg.multicomp(list(trial_df['tau_pval']), method=method, alpha=alpha)\n",
    "\n",
    "        reject = (reject_z & reject_neff) | (reject_z & (trial_df['rule_length'] == 1))\n",
    "        if not hasattr(reject, '__iter__'):\n",
    "            reject = [reject]\n",
    "        sig_df = trial_df[reject]\n",
    "        \n",
    "        if low_cutoff in list(sig_df['cutoff']):\n",
    "            gap_dict['lower_tp'] += 1\n",
    "            gap_dict['tot_lower_tp'] += sig_df[sig_df['cutoff'] == low_cutoff].shape[0]\n",
    "\n",
    "        if upper_cutoff in list(sig_df['cutoff']):\n",
    "            gap_dict['upper_tp'] += 1\n",
    "            gap_dict['tot_upper_tp'] += sig_df[sig_df['cutoff'] == upper_cutoff].shape[0]\n",
    "            \n",
    "        # remaining sig values are false positives\n",
    "        fp_df = sig_df[~sig_df['cutoff'].isin([low_cutoff, upper_cutoff])]\n",
    "        #print(fp_df)\n",
    "        gap_dict['fp'] += fp_df.shape[0]\n",
    "        # for x in fp_df['cutoff'].unique():\n",
    "        #     gap_dict['fp_cutoffs'].add(x)\n",
    "        \n",
    "    nb_dict[gap] = gap_dict\n",
    "    #subgroup_trial_dict[gap] = trial_gap_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.2: {'upper_tp': 32,\n",
       "  'lower_tp': 47,\n",
       "  'fp': 54,\n",
       "  'tot_tests': 18444,\n",
       "  'tot_upper_tp': 33,\n",
       "  'tot_lower_tp': 50},\n",
       " 0.3: {'upper_tp': 116,\n",
       "  'lower_tp': 125,\n",
       "  'fp': 68,\n",
       "  'tot_tests': 18768,\n",
       "  'tot_upper_tp': 121,\n",
       "  'tot_lower_tp': 145},\n",
       " 0.4: {'upper_tp': 269,\n",
       "  'lower_tp': 284,\n",
       "  'fp': 114,\n",
       "  'tot_tests': 18384,\n",
       "  'tot_upper_tp': 312,\n",
       "  'tot_lower_tp': 359},\n",
       " 0.5: {'upper_tp': 440,\n",
       "  'lower_tp': 420,\n",
       "  'fp': 158,\n",
       "  'tot_tests': 17956,\n",
       "  'tot_upper_tp': 619,\n",
       "  'tot_lower_tp': 613},\n",
       " 0.6: {'upper_tp': 496,\n",
       "  'lower_tp': 481,\n",
       "  'fp': 291,\n",
       "  'tot_tests': 17582,\n",
       "  'tot_upper_tp': 862,\n",
       "  'tot_lower_tp': 797},\n",
       " 0.7: {'upper_tp': 500,\n",
       "  'lower_tp': 498,\n",
       "  'fp': 497,\n",
       "  'tot_tests': 17038,\n",
       "  'tot_upper_tp': 973,\n",
       "  'tot_lower_tp': 900}}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(nb_dict, open(os.path.join(RESULTS_DIR, \"rdsgd_neff_results.dict\"), \"wb\"), -1)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c5e384680b37c811d5c050863cd2e1b7b7fb22fa41e6ef4def208bf90ddd8ddd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
